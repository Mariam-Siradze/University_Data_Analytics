{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**აღდგენითი დავალება #2**\n",
        "## **ვადა (deadline): 18 ივნისი 18:00**\n",
        "\n",
        "- თითოეული სავარჯიშო ფასდება შესაბამისი ქულით, რაც ჯამში შეადგენს **7 ქულას**"
      ],
      "metadata": {
        "id": "F1JDwFdXqIvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **სავარჯიშო 1:** ხარისხის კონტროლი ქარხანაში (**1 ქულა**)\n",
        "\n",
        "ქარხანა დღეში აწარმოებს 10,000 დეტალს. ცნობილია, რომ დეტალების 1% დეფექტურია. ზედამხედველი ამოწმებს ერთ დეტალს და ასკვნის, რომ ის დეფექტურია. ზედამხედველის ტესტი 95%-ით ზუსტია (ანუ სწორად ამოიცნობს დეფექტური დეტალების 95%-ს და არადეფექტური დეტალების 95%-ს). რა არის იმის ალბათობა, რომ დეტალი ნამდვილად დეფექტურია?\n",
        "- ამოხსენით ბაიესის ფორმულით.\n",
        "- დაწერეთ შესაბამისი პითონის კოდი."
      ],
      "metadata": {
        "id": "WCdGSAjVK6eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ამოხსნა:**\n",
        "\n",
        "*აქ დაწერეთ ფორმულით ამოხსნა*"
      ],
      "metadata": {
        "id": "KwQopXvYU5ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "P_D = 0.01\n",
        "P_not_D = 0.99\n",
        "P_T_given_D = 0.95\n",
        "P_T_given_not_D = 0.05\n",
        "\n",
        "P_T = (P_T_given_D * P_D) + (P_T_given_not_D * P_not_D)\n",
        "\n",
        "P_D_given_T = (P_T_given_D * P_D) / P_T\n",
        "\n",
        "print(f\"The probability that the part is truly defective given a positive test result is: {P_D_given_T:.4f} or {P_D_given_T * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "fncwsgpvMCnB",
        "outputId": "9899f980-bf95-43af-8390-1df35d8d9706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability that the part is truly defective given a positive test result is: 0.1610 or 16.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **სავარჯიშო 2:** მედიკამენტის ეფექტურობის შეფასება (**1 ქულა**)\n",
        "\n",
        "ფარმაცევტულ კომპანიას სურს შეამოწმოს, არტერიული წნევის დამწევი ახალი მედიკამენტი უფრო ეფექტურია, თუ პლაცებო. ისინი ატარებენ შემთხვევითად კონტროლირებად კვლევას, სადაც პაციენტების ერთი ჯგუფი იღებს მედიკამენტს, ხოლო მეორე ჯგუფი - პლაცებოს. ორივე ჯგუფში იზომება არტერიული წნევის დაწევა.\n",
        "- ქვემოთ მოცემული მონაცემებიდან დათვალეთ და შეადარეთ წნევის დაწევის საშუალო მაჩვენებელი.\n",
        "- ჩამოაყალიბეთ ჰიპოთეზა და გატესტეთ.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgtyG0I8OjoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "bp_reduction_drug = np.array([8, 10, 12, 7, 9, 15, 11, 14, 10, 12])\n",
        "bp_reduction_placebo = np.array([4, 5, 6, 5, 4, 7, 6, 5, 4, 6])\n",
        "\n",
        "mean_drug = np.mean(bp_reduction_drug)\n",
        "mean_placebo = np.mean(bp_reduction_placebo)\n",
        "\n",
        "std_drug = np.std(bp_reduction_drug, ddof=1)\n",
        "std_placebo = np.std(bp_reduction_placebo, ddof=1)\n",
        "\n",
        "t_statistic, p_value = stats.ttest_ind(bp_reduction_drug, bp_reduction_placebo)\n",
        "\n",
        "print(f\"Average blood pressure reduction in the drug group: {mean_drug}\")\n",
        "print(f\"Average blood pressure reduction in the placebo group: {mean_placebo}\")\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The medication is more effective than the placebo.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in effectiveness between the medication and the placebo.\")\n"
      ],
      "metadata": {
        "id": "HS4PQSgBW31T",
        "outputId": "c9f37d89-ca3e-45e7-e896-0d87cc757be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average blood pressure reduction in the drug group: 10.8\n",
            "Average blood pressure reduction in the placebo group: 5.2\n",
            "T-statistic: 6.480740698407861\n",
            "P-value: 4.274848617941792e-06\n",
            "Reject the null hypothesis: The medication is more effective than the placebo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **სავარჯიშო 3:** თანამშრომელთა წარმადობის ანალიზი (**1 ქულა**)\n",
        "\n",
        "კომპანიას სურს გააანალიზოს თანამშრომელთა წარმადობის (performance) მონაცემები (employee_performance.csv), რათა გამოავლინოს საუკეთესო თანამშრომლები, გაიგოს წარმადობის ქულების განაწილება და დაინახოს გაწაფვის პროგრამების გავლენა.\n",
        "- გამოსახეთ წარმადობის ქულების ჰისტოგრამა.\n",
        "- დეპარტამენტების მიხედვით აჩვენეთ წარმადობის ქულების ბოქსპლოტები.\n",
        "- გამოსახეთ წარმადობის ქულების ბოქსპლოტები იმის მიხედვით, მიიღო თუ არა თანამშრომელმა მონაწილეობა გაწაფვის პროგრამაში.\n"
      ],
      "metadata": {
        "id": "uq9aGRIAwAXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv('employee_performance.csv')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['performance_score'], bins=20, kde=True)\n",
        "plt.title('Histogram of Employee Performance Scores')\n",
        "plt.xlabel('Performance Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sDv24Qzk3lR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **სავარჯიშო 4:** ყოველთვიური გაყიდვების ანალიზი (**1 ქულა**)\n",
        "\n",
        "საცალო ვაჭრობის მაღაზიას სურს გააანალიზოს ყოველთვიური გაყიდვების მონაცემები, რათა გაიგოს მისი გაყიდვების განაწილების მოდელი გასული წლის განმავლობაში.\n",
        "-  გამოსახეთ გაყიდვების ჰისტოგრამა და განაწილების ფუნქცია. გამოიყენეთ numpy, scipy.stats და matplotlib.\n",
        "- pandas და scipy.stats-ის მეშვეობით დათვალეთ განაწილების საშუალო, მედიანა, მოდა, დისპერსია, სტანდარტული გადახრა, ასიმეტრია და ექსცესი."
      ],
      "metadata": {
        "id": "TTeGQVChRn3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis, mode\n",
        "\n",
        "np.random.seed(105)\n",
        "monthly_sales = np.random.normal(5000, 1000, 12)\n",
        "\n",
        "df = pd.DataFrame({'Monthly Sales': monthly_sales})\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.hist(df['Monthly Sales'], bins=10, alpha=0.75, edgecolor='black')\n",
        "plt.title('Histogram of Monthly Sales')\n",
        "plt.xlabel('Monthly Sales')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.histplot(df['Monthly Sales'], bins=10, kde=True)\n",
        "plt.title('Histogram and Distribution of Monthly Sales')\n",
        "plt.xlabel('Monthly Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "mean = df['Monthly Sales'].mean()\n",
        "median = df['Monthly Sales'].median()\n",
        "mode_value = mode(df['Monthly Sales'])[0][0]\n",
        "variance = df['Monthly Sales'].var()\n",
        "std_dev = df['Monthly Sales'].std()\n",
        "skewness = skew(df['Monthly Sales'])\n",
        "kurt = kurtosis(df['Monthly Sales'])\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode_value}\")\n",
        "print(f\"Variance: {variance}\")\n",
        "print(f\"Standard Deviation: {std_dev}\")\n",
        "print(f\"Skewness: {skewness}\")\n",
        "print(f\"Kurtosis: {kurt}\")\n"
      ],
      "metadata": {
        "id": "P3IXvmeXTdtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **სავარჯიშო 5:** რეკლამის გავლენა გაყიდვებზე (**3 ქულა**)\n",
        "\n",
        "კომპანიას სურს გაიგოს, როგორ ზემოქმედებს გაყიდვებზე მისი სარეკლამო ბიუჯეტი და რომელია ყველაზე ეფექტური სარეკლამო არხები. მოცემულია მონაცემები advertising.csv:\n",
        "\n",
        "- განსაზღვრეთ წრფივი რეგრესიის ფორმულა.\n",
        "- გაყავით მონაცემები საწვრთნელ და სატესტო ნაწილებად.\n",
        "- გაწვრთენით წრფივი რეგრესიის მოდელი.\n",
        "- სვეტოვანი დიაგრამით გამოსახეთ რეგრესიის კოეფიციენტები.\n",
        "- გაფანტულობის დიაგრამით გამოსახეთ ნამდვილი და მოდელით ნაპროგნოზები გაყიდვების ურთიერთმიმართება.\n",
        "- გამოთვალეთ მოდელის საშუალო კვადრატული ცდომილების ფესვი (RMSE - Root Mean Squared Error), საშუალო აბსოლუტური შეცდომა (MAE - Mean Absolute Error) და $R^2$ (დეტერმინაციის კოეფიციენტი).\n",
        "- გამოიტანეთ დასკვნა, რამდენად კარგი ჩანს მოდელი და რომელი არხია ყველაზე ეფექტური."
      ],
      "metadata": {
        "id": "YQn9UJmQ94j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "data = pd.read_csv('advertising.csv')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "X = data[['TV', 'Radio', 'Newspaper']]\n",
        "y = data['Sales']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "coefficients = pd.Series(model.coef_, index=X.columns)\n",
        "plt.figure(figsize=(10, 6))\n",
        "coefficients.plot(kind='bar')\n",
        "plt.title('Regression Coefficients')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.title('Actual vs Predicted Sales')\n",
        "plt.xlabel('Actual Sales')\n",
        "plt.ylabel('Predicted Sales')\n",
        "plt.show()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R² (coefficient of determination): {r2}\")\n",
        "\n",
        "most_effective_channel = coefficients.idxmax()\n",
        "print(f\"The most effective advertising channel is: {most_effective_channel}\")\n"
      ],
      "metadata": {
        "id": "LmnnboWgGw9P",
        "outputId": "219a9ea6-ff24-48ab-fd84-76046bac9d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           TV      radio  newspaper      sales\n",
            "0  135.281047  46.308182  27.006730  81.481504\n",
            "1  108.003144  47.606208  24.420515  77.812080\n",
            "2  119.574760  60.996596  33.833316  81.747848\n",
            "3  144.817864  56.552637  31.781464  98.743385\n",
            "4  137.351160  56.401315  21.157308  85.681891\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Sales'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sales'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ea0b6e5a3f7>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# X = data[['TV', 'Radio', 'Newspaper']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sales'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8omHbqppVy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EAqyVxYpWoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}